import { NextRequest, NextResponse } from "next/server";
import { InferenceClient } from "@huggingface/inference";
import fs from "fs";
import path from "path";

const client = new InferenceClient(process.env.HF_API_KEY || "");

// Load portfolio content
const portfolioPath = path.join(process.cwd(), "/pfcontent.json");
const portfolioData = JSON.parse(fs.readFileSync(portfolioPath, "utf-8"));

// Predefined casual replies
const casualReplies: Record<string, string> = {
  okay: "ðŸ‘ Got it!",
  ok: "ðŸ‘ Got it!",
  alright: "ðŸ‘Œ Sure thing!",
  thanks: "You're welcome! ðŸ˜Š",
  "thank you": "You're welcome! ðŸ˜Š",
  "got it": "Great! âœ…",
  "i'll get back to you": "No problem, take your time!",
  "that's all": "Alright! Glad I could help.",
  "sounds good": "ðŸ‘ Sounds good!",
  cool: "ðŸ˜Ž Cool!",
  great: "Awesome! ðŸŽ‰",
  nice: "Thanks! ðŸ˜Š",
  sure: "Sure thing! ðŸ‘",
  perfect: "Perfect! âœ…",
  yep: "Got it! ðŸ‘",
  yeah: "Alright! ðŸ˜Š",
  "no worries": "No worries! ðŸ‘",
  "okay then": "Okay! ðŸ‘Œ",
  "thanks a lot": "You're very welcome! ðŸ˜Š",
  "thank you very much": "Anytime! ðŸ˜„",
  awesome: "Glad you think so! ðŸ˜ƒ",
  "alright then": "Alright! ðŸ‘",
  understood: "Understood! âœ…",
  roger: "Roger that! ðŸ‘",
  "cool thanks": "You're welcome! ðŸ˜Ž",
  "ok thanks": "Anytime! ðŸ˜Š",
  "thanks ok": "Sure thing! ðŸ‘",
  gotcha: "Got it! âœ…",
  "oh okay": "ðŸ‘Œ Got it!",
  fine: "Alright! ðŸ˜Š",
  good: "Glad to hear! ðŸ˜„",
  "great job": "Thank you! ðŸ˜Š",
  "well done": "Thanks! ðŸ˜ƒ",
  alrighty: "Alrighty! ðŸ‘",
  "sounds fine": "Sounds good! ðŸ‘",
  "thanks friend": "You're welcome, friend! ðŸ˜Š",
  okie: "Okie! ðŸ‘",
  "ok then": "Alright then! âœ…",
  "no problem": "No problem at all! ðŸ˜„",
  "thanks mate": "You're welcome! ðŸ˜Ž",
  "appreciate it": "Glad to help! ðŸ˜Š",
  "thanks much": "Anytime! ðŸ‘",
  "thank you mate": "You're very welcome! ðŸ˜ƒ",
  "ok sure": "Ok sure! ðŸ‘",
  "ok cool": "Cool! ðŸ˜Ž",
  "got it thanks": "Great! âœ…",
  "alright thanks": "You're welcome! ðŸ˜Š",
  "thanks ok then": "Sure thing! ðŸ‘",
  "ok got it": "Got it! âœ…",
};

export async function POST(req: NextRequest) {
  try {
    const { message } = await req.json();
    const normalized = message.trim().toLowerCase();

    // Check if message matches casual remarks
    for (const key in casualReplies) {
      if (normalized.includes(key)) {
        return NextResponse.json({ reply: casualReplies[key] });
      }
    }

    // Flatten all skill categories into a single array
    const allSkills = Object.values(portfolioData.skills).flat();

    // Construct the system message for the AI
    const systemMessage = {
      role: "system",
      content: `
You are a chatbot that ONLY answers questions about Ikechukwu's portfolio.
Use the following information to answer:

About: ${portfolioData.about}

Projects:
${portfolioData.projects
  .map((p: any) => `${p.name}: ${p.description}`)
  .join("\n")}

Skills: ${allSkills.join(", ")}

Contact:
${
  portfolioData.contact
    ? `
Email: ${portfolioData.contact.email}
Phone: ${portfolioData.contact.phone}
LinkedIn: ${portfolioData.contact.linkedin}
GitHub: ${portfolioData.contact.github}
Twitter: ${portfolioData.contact.twitter}
`
    : "No contact info provided."
}

Rules:
- Only answer questions about Blessing and his portfolio.
- If asked unrelated questions, reply: "I can only answer questions about Blessing."
`,
    };

    // AI chat completion call
    const res = await client.chatCompletion({
      model: "meta-llama/Llama-3.3-70B-Instruct",
      messages: [systemMessage, { role: "user", content: message }],
    });

    return NextResponse.json({
      reply: res.choices?.[0]?.message?.content || "No reply",
    });
  } catch (error: any) {
    console.error("HF API Error:", error);
    return NextResponse.json(
      { reply: "Error generating response" },
      { status: 500 }
    );
  }
}
